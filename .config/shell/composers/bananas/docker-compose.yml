services:
  # Automatic1111 service configuration
  automatic1111:
    build:
      context: ./automatic1111
      dockerfile: Dockerfile
    container_name: automatic1111
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${AUTOMATIC_GPU_DRIVER:-nvidia}
              count: ${AUTOMATIC_GPU_COUNT:-1}
              capabilities:
                - compute
                - gpu
                - utility
      restart_policy:
        condition: on-failure
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
    networks:
      - bananas-network
    ports:
      - "${AUTOMATIC_PORT:-7860}:7860"
    restart: unless-stopped
    runtime: ${AUTOMATIC_GPU_DRIVER:-nvidia}
    tty: true
    volumes:
      - type: bind
        source: ./automatic1111/extensions
        target: /app/extensions
      - type: bind
        source: ./automatic1111/models
        target: /app/models
      - type: bind
        source: ./automatic1111/outputs
        target: /app/outputs
      - type: bind
        source: ./automatic1111/repositories
        target: /app/repositories

  # ComfyUI service configuration
  comfyui:
    build:
      context: ./comfyui
      dockerfile: Dockerfile
    container_name: comfyui
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${AUTOMATIC_GPU_DRIVER:-nvidia}
              count: ${AUTOMATIC_GPU_COUNT:-1}
              capabilities:
                - compute
                - gpu
                - utility
      restart_policy:
        condition: on-failure
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    networks:
      - bananas-network
    ports:
      - "${COMFYUI_PORT:-8188}:8188"
    runtime: ${AUTOMATIC_GPU_DRIVER:+nvidia}
    volumes:
      - type: bind
        source: ./comfyui/custom_nodes
        target: /app/custom_nodes
      - type: bind
        source: ./comfyui/models
        target: /app/models
      - type: bind
        source: ./comfyui/output
        target: /app/output
      - type: bind
        source: ./comfyui/workflows
        target: /app/workflows

  # Ollama service configuration
  ollama:
    container_name: ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${AUTOMATIC_GPU_DRIVER:-nvidia}
              count: ${AUTOMATIC_GPU_COUNT:-1}
              capabilities:
                - compute
                - gpu
                - utility
    image: ollama/ollama:${OLLAMA_DOCKER_TAG:-latest}
    networks:
      - bananas-network
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    restart: unless-stopped
    runtime: ${AUTOMATIC_GPU_DRIVER:+nvidia}
    tty: true
    volumes:
      - type: bind
        source: ./ollama
        target: /root/.ollama

  # OpenWebUI service configuration
  open-webui:
    container_name: open-webui
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUID_SECRET_KEY=''
    extra_hosts:
      - host.docker.internal:host-gateway
    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG:-main}
    networks:
      - bananas-network
    ports:
      - "${WEBUI_PORT:-3000}:8080"
    restart: unless-stopped
    volumes:
      - type: bind
        source: ./open-webui
        target: /app/backend/data

# Define a custom network for inter-service communication
networks:
  bananas-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_ip_masquerade: "true"
      com.docker.network.bridge.name: "br-bananas"

volumes:
  automatic1111:
  comfyui:
  ollama:
  open-webui:
